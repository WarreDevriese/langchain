{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a4b834-2f8b-4507-bfdd-c6069deba1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb504453-eb4e-4c11-89a5-59e6e8598482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e78b387f-f3bb-4bd0-931b-d77c0d6d4083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b910bf7-61c0-4d95-a6a2-f7f397a01b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3e18169-2c4b-4791-a179-182d768e661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92e99978-bfec-4d8b-b2e6-b1a664c4f4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.weatherapi.com/',\n",
       "  'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1716910250, 'localtime': '2024-05-28 8:30'}, 'current': {'last_updated_epoch': 1716910200, 'last_updated': '2024-05-28 08:30', 'temp_c': 12.2, 'temp_f': 54.0, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 10.5, 'wind_kph': 16.9, 'wind_degree': 240, 'wind_dir': 'WSW', 'pressure_mb': 1019.0, 'pressure_in': 30.09, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 86, 'cloud': 75, 'feelslike_c': 11.1, 'feelslike_f': 52.1, 'windchill_c': 10.6, 'windchill_f': 51.1, 'heatindex_c': 11.8, 'heatindex_f': 53.2, 'dewpoint_c': 8.9, 'dewpoint_f': 47.9, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 4.0, 'gust_mph': 15.0, 'gust_kph': 24.1}}\"},\n",
       " {'url': 'https://www.youtube.com/watch?v=IvPtDr4Zrmo',\n",
       "  'content': \"KRON4's meteorologist John Shrable forecasts the weather https://www.kron4.com/weather-san-francisco/\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"what is the weather in SF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cfe5452-1cb1-416d-9723-aa77f8d736bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: numpy in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from faiss-cpu) (1.26.4)\n",
      "Downloading faiss_cpu-1.8.0-cp312-cp312-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93eb0f29-30b1-4f31-9bf5-eb9fe5791137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74c8b44c-a8b9-4920-a4df-d49c966c9fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='description=\"A sample dataset in LangSmith.\")client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"output\": \"Welcome to LangSmith\"},        {\"output\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define your evaluatordef exact_match(run, example):    return {\"score\": run.outputs[\"output\"] == example.outputs[\"output\"]}experiment_results = evaluate(    lambda input: \"Welcome \" + input[\\'postfix\\'], # Your AI system goes here    data=dataset_name, # The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={      \"version\": \"1.0.0\",      \"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"how to upload a dataset\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2416e5e-be3a-4802-b4d9-b83b247e42e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a575432-0e3e-4b53-a9ce-ac4064108390",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d151034-8259-482d-a226-ba66b8c0f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a14389ca-f029-41c8-a8d5-9e280226a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2971b4de-5e2f-4ba1-ac76-8b9783fcb9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c48a7e28-f0b0-4dd1-9687-8bc78aeaed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56f83b83-b91a-44b6-956d-65865b16b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: Hello! How can I assist you today?\n",
      "ToolCalls: []\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "250241d3-1d05-4f61-bd85-d95963589ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: \n",
      "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_OxGpaIXO7x0glKTLsVC0dvez'}]\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF?\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e73f41b6-8ce3-4636-b890-c74d78d1a5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.0.55-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from langgraph) (0.2.1)\n",
      "Collecting uuid6<2025.0.0,>=2024.1.12 (from langgraph)\n",
      "  Downloading uuid6-2024.1.12-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2->langgraph) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2->langgraph) (0.1.63)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2->langgraph) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2->langgraph) (2.7.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2->langgraph) (8.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2->langgraph) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.2->langgraph) (3.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.2->langgraph) (2.32.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.2->langgraph) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.2->langgraph) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.2->langgraph) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.2->langgraph) (2024.2.2)\n",
      "Downloading langgraph-0.0.55-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uuid6-2024.1.12-py3-none-any.whl (6.4 kB)\n",
      "Installing collected packages: uuid6, langgraph\n",
      "Successfully installed langgraph-0.0.55 uuid6-2024.1.12\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "461a430b-29ad-4a03-9abb-ad07a3c92559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import chat_agent_executor\n",
    "\n",
    "agent_executor = chat_agent_executor.create_tool_calling_executor(model, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d9f1feb-fd6e-4337-ad28-8c012e7aa2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', id='705f0de6-e081-4209-999c-c0514e80bf07'),\n",
       " AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 129, 'total_tokens': 139}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5ee62807-3d02-43a3-9f1e-6da8e9421678-0')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51ba0606-969e-41a7-a940-d6e8661136f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='how can langsmith help with testing?', id='0eee26bd-f7b5-46e4-ab43-3967e551fb9c'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_TtJeJt9g5SgrM02z0Ne3BFcO', 'function': {'arguments': '{\\n  \"query\": \"how can LangSmith help with testing?\"\\n}', 'name': 'langsmith_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 135, 'total_tokens': 157}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-07c62a02-e27a-49dd-b6b0-a7573860bd69-0', tool_calls=[{'name': 'langsmith_search', 'args': {'query': 'how can LangSmith help with testing?'}, 'id': 'call_TtJeJt9g5SgrM02z0Ne3BFcO'}]),\n",
       " ToolMessage(content='Get started with LangSmith | 🦜️🛠️ LangSmith\\n\\nSkip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith\\u200bPythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API key\\u200bTo create an API key head to the Settings page. Then click Create API Key.3. Set up your environment\\u200bShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it\\'s not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace\\u200bWe provide multiple ways to log traces to LangSmith. Below, we\\'ll highlight\\n\\nscore: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.\\n\\n\"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators:', name='langsmith_search', id='4901a754-1aba-4cc6-b765-9b2c87f64281', tool_call_id='call_TtJeJt9g5SgrM02z0Ne3BFcO'),\n",
       " AIMessage(content=\"LangSmith is a platform for building production-grade Language Learning Model (LLM) applications. It is designed to closely monitor and evaluate your application, which enables you to launch and deliver with confidence. \\n\\nWhen it comes to testing, LangSmith provides several features:\\n\\n1. **Create Datasets**: You can define your own datasets, which essentially serve as your test cases. This is useful for ensuring your LLM application is producing the expected outputs.\\n\\n2. **Log Traces**: LangSmith provides multiple ways to log traces. This feature can help you trace the execution of your code and understand how your application is functioning in real time.\\n\\n3. **Custom Evaluator**: You can create your own evaluators. For example, in the provided code, an 'exact_match' evaluator is created that checks if the output of a run equals the output of an example.\\n\\n4. **Run Evaluations**: You can use LangSmith to run evaluations of your code against the datasets (test cases) you've created. This makes it easier to automate the testing process and quickly identify any issues or discrepancies.\\n\\n5. **Evaluation Result**: After running the evaluations, you get an Evaluation Result. This helps you understand the performance of your application and make necessary adjustments.\\n\\nIn summary, LangSmith provides a comprehensive set of tools to automate and streamline the testing process of your LLM applications.\", response_metadata={'token_usage': {'completion_tokens': 275, 'prompt_tokens': 818, 'total_tokens': 1093}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2392fe9e-a5c3-4686-a6f1-b7c780f10d0e-0')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"how can langsmith help with testing?\")]}\n",
    ")\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b42e986-0754-4a38-8707-b940412736fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='whats the weather in sf?', id='f5b9a00a-1e4e-470a-a27c-cdedcea8b798'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_u6qiZeWF11TJAEZnKXdh97BQ', 'function': {'arguments': '{\\n  \"query\": \"current weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 134, 'total_tokens': 157}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-002fe8e6-5ae1-4f09-9427-73997214956c-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_u6qiZeWF11TJAEZnKXdh97BQ'}]),\n",
       " ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1716911379, \\'localtime\\': \\'2024-05-28 8:49\\'}, \\'current\\': {\\'last_updated_epoch\\': 1716911100, \\'last_updated\\': \\'2024-05-28 08:45\\', \\'temp_c\\': 12.2, \\'temp_f\\': 54.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 10.5, \\'wind_kph\\': 16.9, \\'wind_degree\\': 240, \\'wind_dir\\': \\'WSW\\', \\'pressure_mb\\': 1019.0, \\'pressure_in\\': 30.09, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 86, \\'cloud\\': 75, \\'feelslike_c\\': 11.1, \\'feelslike_f\\': 52.1, \\'windchill_c\\': 10.6, \\'windchill_f\\': 51.1, \\'heatindex_c\\': 11.8, \\'heatindex_f\\': 53.2, \\'dewpoint_c\\': 8.9, \\'dewpoint_f\\': 47.9, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 4.0, \\'gust_mph\\': 15.0, \\'gust_kph\\': 24.1}}\"}, {\"url\": \"https://forecast.weather.gov/MapClick.php?lat=37.621845878167704&lon=-122.37396240234375&site=mtr&lg=en\", \"content\": \"Current conditions at San Francisco, San Francisco International Airport (KSFO) Lat: 37.61961\\\\u00b0NLon: ... 2024-6pm PDT May 28, 2024 . Forecast Discussion . Additional Resources. Radar & Satellite Image. Hourly Weather Forecast. National Digital Forecast Database. High Temperature. Chance of Precipitation.\"}]', name='tavily_search_results_json', id='716aa953-3782-4a44-82b2-60fdc3f93111', tool_call_id='call_u6qiZeWF11TJAEZnKXdh97BQ'),\n",
       " AIMessage(content='The current weather in San Francisco, California is partly cloudy with a temperature of 12.2°C (54°F). The wind is coming from the WSW at 10.5 mph. The humidity is at 86%. [Source](https://www.weatherapi.com/)', response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 695, 'total_tokens': 752}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7c2c8acd-64f5-4db3-8c61-c98961a45792-0')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
    ")\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13e7301-7bbb-4ac6-ac54-fe4338ad349b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent_executor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[43magent_executor\u001b[49m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m      2\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhats the weather in antwerp?\u001b[39m\u001b[38;5;124m\"\u001b[39m)]}\n\u001b[1;32m      3\u001b[0m ):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(chunk)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agent_executor' is not defined"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in antwerp?\")]}\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "defb061b-2bd3-4f2e-ac46-36560f087ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/warredevriese/Developer/langchain/translator/env/lib/python3.12/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "Starting tool: tavily_search_results_json with inputs: {'query': 'current weather in San Francisco'}\n",
      "Done tool: tavily_search_results_json\n",
      "Tool output was: [{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1716911622, 'localtime': '2024-05-28 8:53'}, 'current': {'last_updated_epoch': 1716911100, 'last_updated': '2024-05-28 08:45', 'temp_c': 12.2, 'temp_f': 54.0, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 10.5, 'wind_kph': 16.9, 'wind_degree': 240, 'wind_dir': 'WSW', 'pressure_mb': 1019.0, 'pressure_in': 30.09, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 86, 'cloud': 75, 'feelslike_c': 11.1, 'feelslike_f': 52.1, 'windchill_c': 10.6, 'windchill_f': 51.1, 'heatindex_c': 11.8, 'heatindex_f': 53.2, 'dewpoint_c': 8.9, 'dewpoint_f': 47.9, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 4.0, 'gust_mph': 15.0, 'gust_kph': 24.1}}\"}, {'url': 'https://forecast.weather.gov/zipcity.php?inputstring=San Francisco, CA', 'content': 'Current conditions at SAN FRANCISCO DOWNTOWN (SFOC1) Lat: 37.77056°NLon: 122.42694°WElev: 150.0ft. NA. 53°F. 12°C. ... 2024-6pm PDT May 28, 2024 . Forecast Discussion . Additional Resources. Radar & Satellite Image. ... National Weather Service; San Francisco Bay Area, CA; 21 Grace Hopper Ave, Stop 5; Monterey, CA 93943-5505; Comments ...'}]\n",
      "--\n",
      "The| current| weather| in| San| Francisco|,| California| is| partly| cloudy| with| a| temperature| of| |12|.|2|°C| (|54|.|0|°F|).| The| wind| is| coming| from| the| W|SW| at| |10|.|5| mph|.| The| humidity| level| is| at| |86|%| with| a| pressure| of| |101|9|.|0| mb|.| The| visibility| is| at| |16|.|0| km|.| [|Source|](|https|://|www|.weather|api|.com|/)|"
     ]
    }
   ],
   "source": [
    "async for event in agent_executor.astream_events(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}, version=\"v1\"\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print(\n",
    "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
    "            )\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
    "            )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d8c5a13-ecb1-4baf-9670-73ce675bfdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db44dbfb-afc9-497f-9d20-5d5b089f5196",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = chat_agent_executor.create_tool_calling_executor(\n",
    "    model, tools, checkpointer=memory\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abd04056-b915-4837-ae3b-752ea03a5cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Hello Bob! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 131, 'total_tokens': 142}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7bba242e-3616-43dc-827f-a7558cfdb001-0')]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b7a5f31-d0b8-457c-a79d-277e1c55acb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Your name is Bob.', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 154, 'total_tokens': 160}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-93afb497-6556-4538-b37b-b3df7f0011dc-0')]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284ff05-59a8-4066-b4b2-d1c8f57c39fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
